#!/bin/sh
set -xa

########################################
# NOS_OFS_AWS  for development work only 
########################################
export HOMEnos=${HOMEnos:-${PACKAGEROOT}/nosofs.${nosofs_ver:?}}
######################################################
# The following two variable could be defined in the
# loadleveler submission script (the sms script), if
# not they will take the default values which is set
# for the NCO running enviroment
#######################################################
export RUN_ENVIR=${RUN_ENVIR:-nco}

###################################
# Specify NET and RUN Name and model
####################################
export envir=prod
export OFS=odaas
export NET=${NET:-nos}
export RUN=${RUN:-$OFS}
export platform=${platform:-H1}
###############################################################
# This block can be modified for different Production test
# environment. This is used for operational testings
###############################################################
export COMROOT=${COMROOT:-/lfs/h1/ops/prod/com}
export DCOMROOT=${DCOMROOT:-/lfs/h1/ops/prod/dcom}
export COMOUT_NAM=/lfs/h1/ops/prod/com/nam/v4.2
#export COMOUT_ETSS=/lfs/h1/ops/prod/com/petss/v1.3
export COMOUT_ETSS=${COMOUT_ETSS:-$(compath.py prod/petss/${petss_ver})}


export PS4='$SECONDS + '
date

####################################
# obtain unique process id (pid) and make temp directory
####################################
export pid=$$
export DATAROOT=${DATAROOT:-/lfs/h1/ops/prod/tmp}
#export DATA=${DATA:-$DATAROOT/${job}.${pid}}
export DATA=${DATA:-${DATAROOT:?}/nos_${OFS}_aws_${cyc}_$envir}
if [ $envir = prod ]; then
  rm -rf ${DATAROOT}/*  
fi
if [ ! -d $DATA ]
then
  mkdir -p $DATA
  cd $DATA
else
  cd $DATA
  rm -fr $DATA/*
fi
mkdir -p $DATA/etss $DATA/nam

cyc=`date -u +"%H"`
if [ $cyc -lt 6 ]; then
    cyc=00
elif [ $cyc -ge 6 -a $cyc -lt 12 ]; then
    cyc=06
elif [ $cyc -ge 12 -a $cyc -lt 18 ]; then
    cyc=12
elif [ $cyc -ge 18 -a $cyc -le 23 ]; then
    cyc=18
fi
#cyc=00
export cycle=t${cyc}z

############################################
#   Determine Job Output Name on System
############################################
export outid="LL$job"
export jobid="${outid}.o${pid}"
export pgmout="OUTPUT.${pid}"

####################################
# Specify Execution Areas
####################################
export EXECnos=${EXECnos:-${HOMEnos}/exec}
export PARMnos=${PARMnos:-${HOMEnos}/parm}
export USHnos=${USHnos:-${HOMEnos}/ush}
export SCRIPTSnos=${SCRIPTSnos:-${HOMEnos}/scripts}
export FIXnos=${FIXnos:-${HOMEnos}/fix/shared}
export FIXofs=${FIXofs:-${HOMEnos}/fix/${OFS}}

###########################################
# Run setpdy and initialize PDY variables
###########################################
sh setpdy.sh
. ./PDY
#export PDY=20210824
##############################################
# Define COM directories
##############################################

#copy ETSS files into work dir
cp -p ${COMOUT_ETSS}/etss.${PDY}/mdlsurge.${cyc}a ${DATA}/etss/.
cp -p ${COMOUT_ETSS}/etss.${PDY}/mdlsurge.${cyc}e ${DATA}/etss/.
cp -p ${COMOUT_ETSS}/etss.${PDY}/mdlsurge.${cyc}g ${DATA}/etss/.
cp -p ${COMOUT_ETSS}/etss.${PDY}/mdlsurge.${cyc}w ${DATA}/etss/.
cp -p ${COMOUT_ETSS}/etss.${PDY}/etss.t${cyc}z.stormsurge.con2p5km.grib2 ${DATA}/etss/.
cp -p ${COMOUT_ETSS}/etss.${PDY}/etss.t${cyc}z.stormsurge.ala3km.grib2 ${DATA}/etss/.
cd $DATA/etss
tar -cvf $DATA/odaas.etss.${PDY}${cyc}.${envir}.wcoss2.tar  *
for HH in 00 03 06 09 12 15 18 21 24 27 30 33 36 39 42 45 48 51 54 57 60 63 66 69 72; do
   cp -p $COMOUT_NAM/nam.${PDY}/nam.t${cyc}z.awip12${HH}.tm00.grib2  ${DATA}/nam/.
done
cd  $DATA/nam
tar -cvf $DATA/odaas.nam.${PDY}${cyc}.${envir}.wcoss2.tar  *
echo started uploading at `date`
aws s3 cp $DATA/odaas.nam.${PDY}${cyc}.${envir}.wcoss2.tar s3://co-ops.nceptransfer/odaas.nam.${PDY}${cyc}.${envir}.wcoss2.tar
aws s3 cp $DATA/odaas.etss.${PDY}${cyc}.${envir}.wcoss2.tar s3://co-ops.nceptransfer/odaas.etss.${PDY}${cyc}.${envir}.wcoss2.tar
export err=$?
if [ $err -ne 0 ] ; then
   echo "File transfer to AWS did not complete normally"
   msg="File transfer to AWS did not complete normally"
   echo "AWS ODAAS DONE 0"
else
   echo "File transfer to AWS completed normally"
   msg="File transfer to AWS completed normally"
   echo "AWS ODAAS DONE 100"
fi

exit

##############################
#cd $DATA_IN
#rm -rf ${DATA}
echo jobid=$jobid
if [ $envir == 'dev' ]; then
  RPTDIR=/lfs/h1/nos/ptmp/$LOGNAME/rpt/${nosofs_ver}
  cp -p ${RPTDIR}/${OFS}_aws_${cyc}.out ${RPTDIR}/${OFS}_aws_${cyc}.out.${}
  cp -p ${RPTDIR}/${OFS}_aws_${cyc}.err ${RPTDIR}/${OFS}_aws_${cyc}.err.${jobid}
elif [ $envir == 'prod' ]; then 
  RPTDIR=/lfs/h1/nos/ptmp/$LOGNAME/rpt/${nosofs_ver}
  cp -p ${RPTDIR}/${OFS}_aws_${cyc}_prod.out ${RPTDIR}/${OFS}_aws_${cyc}_prod.out.${jobid}
  cp -p ${RPTDIR}/${OFS}_aws_${cyc}_prod.err ${RPTDIR}/${OFS}_aws_${cyc}_prod.err.${jobid}  
fi

date


